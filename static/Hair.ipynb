{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import dlib\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from models.Embedding import Embedding\n",
    "from models.Alignment import Alignment\n",
    "from models.Blending import Blending\n",
    "\n",
    "from utils.drive import open_url\n",
    "from utils.shape_predictor import align_face\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "align_args = Namespace(unprocessed_dir = 'unprocessed', output_dir = 'input/face', output_size = 1024,\n",
    " cache_dir = 'cache', inter_method = 'bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Shape Predictor\n"
     ]
    }
   ],
   "source": [
    "#Loading Shape Predictor for Alignment\n",
    "cache_dir = Path(align_args.cache_dir)\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_dir = Path(align_args.output_dir)\n",
    "output_dir.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "print(\"Downloading Shape Predictor\")\n",
    "f=open_url(\"https://drive.google.com/uc?id=1huhv8PYpNNKbGCLOaYUjOgR1pY5pmbJx\", cache_dir=cache_dir, return_path=True)\n",
    "predictor = dlib.shape_predictor(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot write mode RGBA as JPEG",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/mnt/d/Programming/miniconda3/envs/Barbershop/lib/python3.7/site-packages/PIL/JpegImagePlugin.py\u001B[0m in \u001B[0;36m_save\u001B[0;34m(im, fp, filename)\u001B[0m\n\u001B[1;32m    628\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 629\u001B[0;31m         \u001B[0mrawmode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRAWMODE\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    630\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'RGBA'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_2663/4225662975.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcrop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m448\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m28\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1472\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1052\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mimg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'unprocessed/{name}.jpg'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/mnt/d/Programming/miniconda3/envs/Barbershop/lib/python3.7/site-packages/PIL/Image.py\u001B[0m in \u001B[0;36msave\u001B[0;34m(self, fp, format, **params)\u001B[0m\n\u001B[1;32m   2233\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2234\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2235\u001B[0;31m             \u001B[0msave_handler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2236\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2237\u001B[0m             \u001B[0;31m# do what we can to clean up\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/mnt/d/Programming/miniconda3/envs/Barbershop/lib/python3.7/site-packages/PIL/JpegImagePlugin.py\u001B[0m in \u001B[0;36m_save\u001B[0;34m(im, fp, filename)\u001B[0m\n\u001B[1;32m    629\u001B[0m         \u001B[0mrawmode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRAWMODE\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    630\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 631\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mOSError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"cannot write mode {im.mode} as JPEG\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    632\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    633\u001B[0m     \u001B[0minfo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoderinfo\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mOSError\u001B[0m: cannot write mode RGBA as JPEG"
     ]
    }
   ],
   "source": [
    "#Automatic Image Cropper\n",
    "\n",
    "name: str = 'image'\n",
    "\n",
    "img = Image.open(f'unprocessed/{name}.jpg')\n",
    "\n",
    "img = img.crop((448, 28, 1472, 1052))\n",
    "img.save(f'unprocessed/{name}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.jpg: Number of faces detected: 1\n",
      "Maya.jpg: Number of faces detected: 1\n",
      "test.jpg: Number of faces detected: 0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for im in Path(align_args.unprocessed_dir).glob(\"*.*\"):\n",
    "       faces = align_face(str(im),predictor)\n",
    "       \n",
    "       for i,face in enumerate(faces):\n",
    "           if(align_args.output_size):\n",
    "               factor = 1024//align_args.output_size\n",
    "               assert align_args.output_size*factor == 1024\n",
    "               face_tensor = torchvision.transforms.ToTensor()(face).unsqueeze(0).cuda()\n",
    "               face_tensor_lr = face_tensor[0].cpu().detach().clamp(0, 1)\n",
    "               face = torchvision.transforms.ToPILImage()(face_tensor_lr)\n",
    "               if factor != 1:\n",
    "                   face = face.resize((align_args.output_size, align_args.output_size), Image.LANCZOS)\n",
    "           if len(faces) > 1:\n",
    "               face.save(Path(align_args.output_dir) / (im.stem+f\"_{i}.png\"))\n",
    "           else:\n",
    "               face.save(Path(align_args.output_dir) / (im.stem + f\".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# I/O arguments\n",
    "ref: str = 'image.png'\n",
    "tgt: str = f'{id}.png'\n",
    "\n",
    "args = Namespace(input_dir='input/face', output_dir='output', im_path1 = ref, im_path2=tgt, im_path3= tgt,\n",
    " sign='realistic', smooth=5, size=1024, ckpt='pretrained_models/ffhq.pt', channel_multiplier=2,\n",
    "  latent=512, n_mlp=8, device='cuda', seed=None, tile_latent=False, opt_name='adam',\n",
    "   learning_rate=0.01, lr_schedule='fixed', save_intermediate=False, save_interval=300,\n",
    "    verbose=False, seg_ckpt='pretrained_models/seg.pth', percept_lambda=1.0, l2_lambda=1.0,\n",
    "     p_norm_lambda=0.001, l_F_lambda=0.1, W_steps=250, FS_steps=250, ce_lambda=1.0, style_lambda=40000.0,\n",
    "      align_steps1=100, align_steps2=100, face_lambda=1.0, hair_lambda=1.0, blend_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "im_path1 = os.path.join(args.input_dir, args.im_path1)\n",
    "im_path2 = os.path.join(args.input_dir, args.im_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading StyleGAN2 from checkpoint: pretrained_models/ffhq.pt\n",
      "Setting up Perceptual loss...\n",
      "Loading model from: /mnt/d/Programming/Spectrum/Barbershop/Barbershop/losses/lpips/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n",
      "Number of images: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:57<00:00, 57.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:48<00:00, 48.87s/it]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Embed input image\n",
    "ii2s = Embedding(args)\n",
    "\n",
    "im_set = {im_path1}\n",
    "ii2s.invert_images_in_W([*im_set])\n",
    "ii2s.invert_images_in_FS([*im_set])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading StyleGAN2 from checkpoint: pretrained_models/ffhq.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Align Step 2:   0%|                                                                             | 0/100 [00:00<?, ?it/s]/mnt/d/Programming/miniconda3/envs/Barbershop/lib/python3.7/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "/mnt/d/Programming/miniconda3/envs/Barbershop/lib/python3.7/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "#Alignment Step\n",
    "\n",
    "align = Alignment(args)\n",
    "align.align_images(im_path1, im_path2, sign=args.sign, align_more_region=False, smooth=args.smooth)\n",
    "\n",
    "#originalimage_chosenimage.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading StyleGAN2 from checkpoint: pretrained_models/ffhq.pt\n",
      "Setting up Perceptual loss...\n",
      "Loading model from: /mnt/d/Programming/Spectrum/Barbershop/Barbershop/losses/masked_lpips/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n",
      "Setting up Perceptual loss...\n",
      "Loading model from: /mnt/d/Programming/Spectrum/Barbershop/Barbershop/losses/masked_lpips/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    }
   ],
   "source": [
    "blend = Blending(args)\n",
    "blend.blend_images(im_path1, im_path2, im_path2, sign=args.sign)\n",
    "#originalimage_chosenimage_chosenimage.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}